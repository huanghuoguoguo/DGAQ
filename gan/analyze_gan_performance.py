#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GANå¯¹æŠ—æ”»å‡»æ€§èƒ½åˆ†æè„šæœ¬
æµ‹è¯•ä¸åŒepochçš„ç”Ÿæˆå™¨å¯¹å¤šä¸ªç›®æ ‡æ¨¡å‹çš„æ”»å‡»æ•ˆæœ
"""

import os
import sys
import torch
import glob
import argparse
from tqdm import tqdm

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from core.model.cnn_model import LightweightCNN
from core.adversarial.generator import DGAGenerator
from core.dataset import load_dataset

def load_target_model(model_path, device, vocab_size=41, num_classes=2):
    """åŠ è½½ç›®æ ‡åˆ†ç±»å™¨ï¼Œæ”¯æŒCNNä¸CNN-MoE"""
    model = None
    try:
        if 'cnn_moe' in os.path.basename(model_path):
            from core.model.cnn_moe_model import LightweightCNNMoE
            model = LightweightCNNMoE(
                vocab_size=vocab_size,
                embedding_dim=128,
                max_length=60,
                num_classes=num_classes,
                num_experts=3
            ).to(device)
        else:
            from core.model.cnn_model import LightweightCNN
            model = LightweightCNN(
                vocab_size=vocab_size,
                embedding_dim=128,
                max_length=60,
                num_classes=num_classes
            ).to(device)
        
        if os.path.exists(model_path):
            state = torch.load(model_path, map_location=device, weights_only=False)
            model.load_state_dict(state)
            model.eval()
            return model
        else:
            raise FileNotFoundError(f"Model not found: {model_path}")
    except Exception as e:
        raise e

def load_generator(model_path, device, vocab_size=41, hidden_dim=256, max_len=60, z_dim=100):
    """åŠ è½½ç”Ÿæˆå™¨"""
    generator = DGAGenerator(
        vocab_size=vocab_size,
        hidden_dim=hidden_dim,
        max_len=max_len,
        z_dim=z_dim
    ).to(device)
    
    if os.path.exists(model_path):
        generator.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))
        generator.eval()
        return generator
    else:
        raise FileNotFoundError(f"Generator not found: {model_path}")

def evaluate_attack(generator, target_model, device, num_samples=1000):
    """è¯„ä¼°æ”»å‡»æ•ˆæœ"""
    with torch.no_grad():
        # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
        adv_indices = generator.sample(num_samples, device)
        
        # ç›®æ ‡æ¨¡å‹é¢„æµ‹
        logits = target_model(adv_indices)
        probs = torch.softmax(logits, dim=1)
        predictions = torch.argmax(probs, dim=1)
        
        # è®¡ç®—ASR (å‡è®¾0=è‰¯æ€§ï¼Œ1=æ¶æ„ï¼Œæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆçš„æ¶æ„æ ·æœ¬è¢«è¯¯åˆ†ç±»ä¸ºè‰¯æ€§)
        successful_evasions = (predictions == 0).sum().item()
        asr = successful_evasions / num_samples
        
        # è®¡ç®—ç½®ä¿¡åº¦ç»Ÿè®¡
        benign_confidence = probs[:, 0].mean().item()
        malicious_confidence = probs[:, 1].mean().item()
        
        return {
            'asr': asr,
            'evasions': successful_evasions,
            'detections': num_samples - successful_evasions,
            'benign_conf': benign_confidence,
            'malicious_conf': malicious_confidence
        }

def main():
    parser = argparse.ArgumentParser(description="åˆ†æGANæ”»å‡»æ€§èƒ½")
    parser.add_argument('--gan_dir', type=str, default='./models/gan', help='GANæ¨¡å‹ç›®å½•')
    parser.add_argument('--target_models', nargs='+', 
                       default=['./models/cnn_binary_model.pth'],
                       help='ç›®æ ‡æ¨¡å‹è·¯å¾„åˆ—è¡¨')
    parser.add_argument('--num_samples', type=int, default=1000, help='æµ‹è¯•æ ·æœ¬æ•°')
    parser.add_argument('--epochs_to_test', nargs='+', type=int,
                       default=[5, 10, 15, 20, 25, 30, 35, 40, 45, 50],
                       help='è¦æµ‹è¯•çš„epochåˆ—è¡¨')
    args = parser.parse_args()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {args.num_samples}")
    print("="*60)
    
    # è·å–æ‰€æœ‰ç”Ÿæˆå™¨checkpoint
    generator_files = sorted(glob.glob(os.path.join(args.gan_dir, 'generator_epoch_*.pth')))
    
    # ç­›é€‰æŒ‡å®šepoch
    generators_to_test = []
    for epoch in args.epochs_to_test:
        gen_path = os.path.join(args.gan_dir, f'generator_epoch_{epoch}.pth')
        if os.path.exists(gen_path):
            generators_to_test.append((epoch, gen_path))
    
    if not generators_to_test:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç”Ÿæˆå™¨checkpoint")
        return
    
    print(f"æ‰¾åˆ° {len(generators_to_test)} ä¸ªç”Ÿæˆå™¨checkpoint")
    print(f"ç›®æ ‡æ¨¡å‹æ•°: {len(args.target_models)}\n")
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # å¯¹æ¯ä¸ªç›®æ ‡æ¨¡å‹è¿›è¡Œæµ‹è¯•
    for target_path in args.target_models:
        model_name = os.path.basename(target_path).replace('.pth', '')
        print(f"\n{'='*60}")
        print(f"ç›®æ ‡æ¨¡å‹: {model_name}")
        print(f"{'='*60}")
        
        if not os.path.exists(target_path):
            print(f"âš ï¸ è·³è¿‡ï¼ˆæ¨¡å‹ä¸å­˜åœ¨ï¼‰: {target_path}")
            continue
        
        # åŠ è½½ç›®æ ‡æ¨¡å‹
        target_model = load_target_model(target_path, device)
        results[model_name] = []
        
        # æµ‹è¯•æ¯ä¸ªepochçš„ç”Ÿæˆå™¨
        for epoch, gen_path in tqdm(generators_to_test, desc=f"æµ‹è¯• {model_name}"):
            try:
                generator = load_generator(gen_path, device)
                metrics = evaluate_attack(generator, target_model, device, args.num_samples)
                
                results[model_name].append({
                    'epoch': epoch,
                    **metrics
                })
                
                print(f"  Epoch {epoch:2d}: ASR={metrics['asr']*100:5.2f}%, "
                      f"é€ƒé€¸={metrics['evasions']:4d}, "
                      f"æ£€æµ‹={metrics['detections']:4d}, "
                      f"è‰¯æ€§ç½®ä¿¡åº¦={metrics['benign_conf']:.3f}")
                
            except Exception as e:
                print(f"  Epoch {epoch:2d}: é”™è¯¯ - {e}")
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print(f"\n\n{'='*60}")
    print("ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Š")
    print(f"{'='*60}\n")
    
    for model_name, model_results in results.items():
        if not model_results:
            continue
        
        print(f"ç›®æ ‡æ¨¡å‹: {model_name}")
        print("-" * 60)
        
        # æ‰¾åˆ°æœ€ä½³ASR
        best_result = max(model_results, key=lambda x: x['asr'])
        worst_result = min(model_results, key=lambda x: x['asr'])
        
        print(f"  æœ€ä½³ ASR: {best_result['asr']*100:.2f}% (Epoch {best_result['epoch']})")
        print(f"  æœ€å·® ASR: {worst_result['asr']*100:.2f}% (Epoch {worst_result['epoch']})")
        
        # ASRè¶‹åŠ¿åˆ†æ
        asrs = [r['asr'] for r in model_results]
        epochs = [r['epoch'] for r in model_results]
        
        if len(asrs) > 1:
            # è®¡ç®—ASRå¢é•¿ç‡
            asr_growth = (asrs[-1] - asrs[0]) / asrs[0] * 100 if asrs[0] > 0 else 0
            print(f"  ASRå¢é•¿ç‡: {asr_growth:+.2f}% (Epoch {epochs[0]} â†’ {epochs[-1]})")
            
            # åˆ¤æ–­æ”¶æ•›æƒ…å†µ
            if len(asrs) >= 3:
                last_3_var = sum((asrs[i] - asrs[i-1])**2 for i in range(-3, 0)) / 3
                if last_3_var < 0.001:
                    print(f"  æ”¶æ•›çŠ¶æ€: âœ… å·²æ”¶æ•› (æœ€å3è½®æ–¹å·®={last_3_var:.6f})")
                else:
                    print(f"  æ”¶æ•›çŠ¶æ€: ğŸ”„ ä»åœ¨ä¼˜åŒ– (æœ€å3è½®æ–¹å·®={last_3_var:.6f})")
        
        print()
    
    # ç»™å‡ºä¸‹ä¸€æ­¥å»ºè®®
    print(f"\n{'='*60}")
    print("ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®")
    print(f"{'='*60}\n")
    
    for model_name, model_results in results.items():
        if not model_results or len(model_results) < 2:
            continue
        
        asrs = [r['asr'] for r in model_results]
        epochs = [r['epoch'] for r in model_results]
        
        print(f"{model_name}:")
        
        # å»ºè®®1: è®­ç»ƒè½®æ•°
        if asrs[-1] > asrs[-2]:
            print(f"  âœ… ASRä»åœ¨ä¸Šå‡ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒè‡³ Epoch {epochs[-1] + 20}")
        else:
            print(f"  âš ï¸ ASRä¸‹é™ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆï¼Œå»ºè®®ä½¿ç”¨ Epoch {epochs[asrs.index(max(asrs))]} çš„æ¨¡å‹")
        
        # å»ºè®®2: ASRæ°´å¹³è¯„ä¼°
        best_asr = max(asrs)
        if best_asr < 0.3:
            print(f"  ğŸ“ˆ å½“å‰æœ€ä½³ASR={best_asr*100:.1f}%è¾ƒä½ï¼Œå»ºè®®:")
            print(f"     - è°ƒæ•´å­¦ä¹ ç‡ (å½“å‰1e-4ï¼Œå¯å°è¯•5e-5æˆ–2e-4)")
            print(f"     - å¢åŠ ç”Ÿæˆå™¨hidden_dim (å½“å‰256ï¼Œå¯å°è¯•512)")
            print(f"     - è°ƒæ•´n_criticæ¯”ä¾‹ (å½“å‰5ï¼Œå¯å°è¯•3æˆ–7)")
        elif best_asr < 0.5:
            print(f"  ğŸ¯ å½“å‰æœ€ä½³ASR={best_asr*100:.1f}%ä¸­ç­‰ï¼Œç»§ç»­ä¼˜åŒ–æœ‰æ½œåŠ›")
        else:
            print(f"  ğŸ‰ å½“å‰æœ€ä½³ASR={best_asr*100:.1f}%ä¼˜ç§€ï¼Œæ”»å‡»æ•ˆæœæ˜¾è‘—")
        
        # å»ºè®®3: è¿ç§»æ€§æµ‹è¯•
        if len(args.target_models) == 1:
            print(f"  ğŸ”¬ å»ºè®®æµ‹è¯•å¯¹å…¶ä»–æ¨¡å‹çš„è¿ç§»æ”»å‡»èƒ½åŠ›:")
            print(f"     - Mamba2: ./models/mamba2_binary_model.pth")
            print(f"     - CNN-MoE: ./models/cnn_moe_binary_model.pth")
        
        print()

if __name__ == "__main__":
    main()
