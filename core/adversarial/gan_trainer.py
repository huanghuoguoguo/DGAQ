import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import os
from tqdm import tqdm
from .generator import DGAGenerator
from .discriminator import DGADiscriminator

class WGAN_GP_Trainer:
    """
    WGAN-GP è®­ç»ƒå™¨
    """
    def __init__(self, config, device):
        self.config = config
        self.device = device
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.generator = DGAGenerator(
            vocab_size=config['vocab_size'],
            hidden_dim=config['hidden_dim'],
            max_len=config['max_len'],
            z_dim=config['z_dim']
        ).to(device)
        
        self.discriminator = DGADiscriminator(
            vocab_size=config['vocab_size'],
            hidden_dim=config['hidden_dim'],
            max_len=config['max_len']
        ).to(device)
        
        # ä¼˜åŒ–å™¨
        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=config['lr'], betas=(0.5, 0.9))
        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=config['lr'], betas=(0.5, 0.9))
        
        # é…ç½®å‚æ•°
        self.lambda_gp = config.get('lambda_gp', 10)
        self.n_critic = config.get('n_critic', 5)
        self.batch_size = config['batch_size']
        self.vocab_size = config['vocab_size']
        self.max_len = config['max_len']

    def compute_gradient_penalty(self, real_samples, fake_samples):
        """
        è®¡ç®—æ¢¯åº¦æƒ©ç½š (Gradient Penalty)
        """
        # éšæœºæƒé‡ alpha: (batch_size, 1, 1)
        alpha = torch.rand((real_samples.size(0), 1, 1)).to(self.device)
        
        # åœ¨çœŸå®æ ·æœ¬å’Œç”Ÿæˆæ ·æœ¬ä¹‹é—´è¿›è¡Œæ’å€¼
        interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)
        
        # åˆ¤åˆ«å™¨å¯¹æ’å€¼æ ·æœ¬çš„è¾“å‡º
        d_interpolates = self.discriminator(interpolates)
        
        # è®¡ç®—æ¢¯åº¦
        fake = torch.ones((real_samples.size(0), 1)).to(self.device)
        gradients = torch.autograd.grad(
            outputs=d_interpolates,
            inputs=interpolates,
            grad_outputs=fake,
            create_graph=True,
            retain_graph=True,
            only_inputs=True,
        )[0]
        
        # è®¡ç®—æ¢¯åº¦çš„èŒƒæ•°
        gradients = gradients.view(gradients.size(0), -1)
        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
        
        return gradient_penalty

    def train(self, dataloader, epochs=100, save_path='./models/gan'):
        """
        è®­ç»ƒå¾ªç¯
        """
        if not os.path.exists(save_path):
            os.makedirs(save_path)
            
        print(f"ğŸš€ å¼€å§‹ WGAN-GP è®­ç»ƒ... (Epochs: {epochs})")
        
        for epoch in range(epochs):
            pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Epoch {epoch+1}/{epochs}")
            
            for i, (real_seqs, _) in pbar:
                batch_size = real_seqs.size(0)
                real_seqs = real_seqs.to(self.device)
                
                # å°†ç´¢å¼•åºåˆ—è½¬æ¢ä¸º One-Hot ç¼–ç  (batch, max_len, vocab_size)
                real_one_hot = F.one_hot(real_seqs, num_classes=self.vocab_size).float()
                
                # ================================================================== #
                #                      1. è®­ç»ƒ Discriminator (Critic)                #
                # ================================================================== #
                
                self.d_optimizer.zero_grad()
                
                # ç”Ÿæˆå‡æ ·æœ¬ (Softmax Probabilities)
                fake_probs = self.generator(batch_size, self.device)
                
                # åˆ¤åˆ«å™¨æ‰“åˆ†
                real_validity = self.discriminator(real_one_hot)
                fake_validity = self.discriminator(fake_probs.detach()) # Detach to avoid training G
                
                # æ¢¯åº¦æƒ©ç½š
                gradient_penalty = self.compute_gradient_penalty(real_one_hot, fake_probs.detach())
                
                # Adversarial Loss (Wasserstein Distance)
                # Minimize - (E[D(x)] - E[D(G(z))]) + lambda * GP
                d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + self.lambda_gp * gradient_penalty
                
                d_loss.backward()
                self.d_optimizer.step()
                
                # ================================================================== #
                #                        2. è®­ç»ƒ Generator                           #
                # ================================================================== #
                
                # æ¯ n_critic æ¬¡æ›´æ–°ä¸€æ¬¡ Generator
                if i % self.n_critic == 0:
                    self.g_optimizer.zero_grad()
                    
                    # é‡æ–°ç”Ÿæˆå‡æ ·æœ¬ (ä¿ç•™æ¢¯åº¦)
                    fake_probs = self.generator(batch_size, self.device)
                    
                    # åˆ¤åˆ«å™¨æ‰“åˆ†
                    fake_validity = self.discriminator(fake_probs)
                    
                    # Generator Loss
                    # Minimize - E[D(G(z))]
                    g_loss = -torch.mean(fake_validity)
                    
                    g_loss.backward()
                    self.g_optimizer.step()
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({
                        'D Loss': d_loss.item(), 
                        'G Loss': g_loss.item()
                    })
            
            # æ¯ä¸ª Epoch ä¿å­˜ä¸€æ¬¡æ¨¡å‹
            if (epoch + 1) % 5 == 0:
                torch.save(self.generator.state_dict(), os.path.join(save_path, f'generator_epoch_{epoch+1}.pth'))
                torch.save(self.discriminator.state_dict(), os.path.join(save_path, f'discriminator_epoch_{epoch+1}.pth'))
                
                # ç”Ÿæˆä¸€äº›æ ·æœ¬çœ‹çœ‹æ•ˆæœ
                self.generate_samples(5)

    def generate_samples(self, num_samples=5):
        """
        ç”Ÿæˆå¹¶æ‰“å°æ ·æœ¬
        """
        indices = self.generator.sample(num_samples, self.device)
        # è¿™é‡Œéœ€è¦ä¸€ä¸ª index_to_char çš„æ˜ å°„ï¼Œæš‚æ—¶æ‰“å°ç´¢å¼•æˆ–éœ€è¦ä¼ å…¥ vocab
        print(f"\n[Sample Indices]: {indices[0].cpu().numpy()}")
        # TODO: Decode to string if vocab is available
